{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f8491e1-f80d-4b6d-9525-02771661ecd4",
   "metadata": {},
   "source": [
    "# Genera el XML de las personas\n",
    "\n",
    "## Resumen del Código para Generar el Archivo XML con LBPH\r\n",
    "Reconocedor de rostros.a:\r\n",
    "\r\n",
    "1. **Importación de Librerías:**\r\n",
    "   - `cv2` para el procesamiento de imágenes.\r\n",
    "   - `numpy` para manejo de arreglos.\r\n",
    "   - `os` para manejo del sistema de archivos.\r\n",
    "\r\n",
    "2. **Definición del Conjunto de Datos:**\r\n",
    "   - Se especifica la ruta del directorio con subdirectorios que contienen imágenes etiquetadas de rostros.\r\n",
    "\r\n",
    "3. **Lectura y Procesamiento de Datos:**\r\n",
    "   - Se obtiene una lista de los nombres de los subdirectorios (cada uno representando una persona).\r\n",
    "   - Se inicializan listas para almacenar las etiquetas y los datos de las imágenes.\r\n",
    "   - Para cada subdirectorio, se leen las imágenes en escala de grises y se almacenan junto con sus etiquetas correspondientes.\r\n",
    "\r\n",
    "4. **Entrenamiento del Modelo:**\r\n",
    "   - Se crea un reconocedor facial LBPH.\r\n",
    "   - Se entrena el reconocedor con las imágenes (`facesData`) y sus etiquetas (`labels`).\r\n",
    "\r\n",
    "5. **Guardado del Modelo:**\r\n",
    "   - El modelo entrenado se guarda en un archivo XML (`LBPHPersonesFix.xml`) para su uso posterior.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a3ab17-e013-4c31-b2e8-974228876274",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv \n",
    "import numpy as np \n",
    "import os\n",
    "\n",
    "# Ruta del conjunto de datos que contiene las imágenes etiquetadas de los rostros\n",
    "dataSet = 'D:\\\\Escuela Betin\\\\9no Sem\\\\3. Inteligencia Artificial\\\\Rostros\\\\Persones'\n",
    "\n",
    "# Obtener los nombres de los directorios dentro del conjunto de datos\n",
    "faces = os.listdir(dataSet)\n",
    "print(faces)\n",
    "\n",
    "# Inicializar listas para las etiquetas y los datos de las caras\n",
    "labels = []\n",
    "facesData = []\n",
    "label = 0 \n",
    "\n",
    "# Iterar sobre cada directorio en el conjunto de datos\n",
    "for face in faces:\n",
    "    facePath = dataSet + '\\\\' + face  # Ruta del directorio de cada persona\n",
    "    for faceName in os.listdir(facePath):\n",
    "        labels.append(label)  # Agregar la etiqueta correspondiente a la lista de etiquetas\n",
    "        # Leer la imagen en escala de grises y agregarla a la lista de datos de caras\n",
    "        facesData.append(cv.imread(facePath + '\\\\' + faceName, 0))\n",
    "    label = label + 1  # Incrementar la etiqueta para la siguiente persona\n",
    "\n",
    "# Crear un reconocedor facial LBPH\n",
    "faceRecognizer = cv.face.LBPHFaceRecognizer_create()\n",
    "\n",
    "# Entrenar el reconocedor con los datos de las caras y sus etiquetas\n",
    "faceRecognizer.train(facesData, np.array(labels))\n",
    "\n",
    "# Guardar el modelo entrenado en un archivo XML\n",
    "faceRecognizer.write('D:\\\\Escuela Betin\\\\9no Sem\\\\3. Inteligencia Artificial\\\\Rostros\\\\LBPHPersonesFix.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09c9823-7785-47c8-b307-d1be22ae36ea",
   "metadata": {},
   "source": [
    "# Corre el XML \n",
    "\n",
    "## Resumen del Código para Reconocimiento Facial en Tiempo Reala:\r\n",
    "\r\n",
    "1. **Importación de Librerías:**\r\n",
    "   - `cv2` para procesamiento de imágenes.\r\n",
    "   - `os` para manejo de archivos del sistema.\r\n",
    "\r\n",
    "2. **Carga del Modelo:**\r\n",
    "   - Se crea un reconocedor LBPH y se carga un modelo preentrenado desde un archivo XML.\r\n",
    "\r\n",
    "3. **Preparación del Conjunto de Datos:**\r\n",
    "   - Se especifica la ruta del directorio que contiene las imágenes etiquetadas de rostros.\r\n",
    "\r\n",
    "4. **Inicialización de la Cámara:**\r\n",
    "   - Se inicia la captura de video desde la cámara web.\r\n",
    "   - Se carga un clasificador Haar para la detección de rostros.\r\n",
    "\r\n",
    "5. **Procesamiento en Tiempo Real:**\r\n",
    "   - Se captura y procesa cada fotograma de la cámara.\r\n",
    "   - Se convierte el fotograma a escala de grises y se detectan rostros.\r\n",
    "\r\n",
    "6. **Reconocimiento Facial:**\r\n",
    "   - Se extrae, redimensiona y predice la región de interés de cada rostro detectado.\r\n",
    "   - Se muestran los resultados en el fotograma, etiquetando los rostros como conocidos o desconocidos.\r\n",
    "\r\n",
    "7. **Visualización y Salida:**\r\n",
    "   - Se muestra el fotograma con los resultados en una ventana.\r\n",
    "   - Se espera la tecla 'Esc' para finalizar el programa.\r\n",
    "\r\n",
    "8. **Liberación de Recursos:**\r\n",
    "   - Se liberan los recursos de la cámara y se cierran las ventanas de OpenCV.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11104cf0-2439-4377-b2c0-f0e1b27a2ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import os \n",
    "\n",
    "# Crear el reconocedor facial LBPH y cargar el modelo preentrenado desde un archivo XML\n",
    "faceRecognizer = cv.face.LBPHFaceRecognizer_create()\n",
    "faceRecognizer.read('D:\\\\Escuela Betin\\\\9no Sem\\\\3. Inteligencia Artificial\\\\Rostros\\\\LBPHPersonesFix.xml')\n",
    "\n",
    "# Definir la ruta del conjunto de datos que contiene las etiquetas de las caras\n",
    "dataSet = 'D:\\\\Escuela Betin\\\\9no Sem\\\\3. Inteligencia Artificial\\\\Rostros\\\\Persones'\n",
    "faces = os.listdir(dataSet)  # Obtener los nombres de los archivos en el directorio\n",
    "\n",
    "# Iniciar la captura de video desde la cámara web\n",
    "cap = cv.VideoCapture(0)\n",
    "\n",
    "# Cargar el clasificador Haar para la detección de rostros\n",
    "rostro = cv.CascadeClassifier('D:\\\\Escuela Betin\\\\9no Sem\\\\3. Inteligencia Artificial\\\\Material de clase\\\\haarcascade_frontalface_alt.xml')\n",
    "\n",
    "while True:\n",
    "    # Leer un fotograma de la cámara\n",
    "    ret, frame = cap.read()\n",
    "    if ret == False: \n",
    "        break  # Salir del bucle si no se puede leer el fotograma\n",
    "\n",
    "    # Convertir el fotograma a escala de grises\n",
    "    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    cpGray = gray.copy()  # Hacer una copia de la imagen en grises\n",
    "\n",
    "    # Detectar rostros en la imagen en escala de grises\n",
    "    rostros = rostro.detectMultiScale(gray, 1.3, 3)\n",
    "    \n",
    "    for (x, y, w, h) in rostros:\n",
    "        # Extraer la región de interés (ROI) que contiene el rostro detectado\n",
    "        frame2 = cpGray[y:y+h, x:x+w]\n",
    "        \n",
    "        # Redimensionar la ROI a 100x100 píxeles\n",
    "        frame2 = cv.resize(frame2, (100, 100), interpolation=cv.INTER_CUBIC)\n",
    "        \n",
    "        # Realizar la predicción de la cara utilizando el modelo LBPH\n",
    "        result = faceRecognizer.predict(frame2)\n",
    "        \n",
    "        # Mostrar el resultado de la predicción en el fotograma\n",
    "        cv.putText(frame, '{}'.format(result), (x, y-20), 1, 3.3, (255, 255, 0), 1, cv.LINE_AA)\n",
    "        \n",
    "        if result[1] < 100:\n",
    "            # Si la confianza es menor a 100, se considera una coincidencia y se muestra el nombre\n",
    "            cv.putText(frame, '{}'.format(faces[result[0]]), (x, y-25), 2, 1.1, (0, 255, 0), 1, cv.LINE_AA)\n",
    "            cv.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        else:\n",
    "            # Si la confianza es mayor o igual a 100, se considera \"Desconocido\"\n",
    "            cv.putText(frame, 'Desconocido', (x, y-20), 2, 0.8, (0, 0, 255), 1, cv.LINE_AA)\n",
    "            cv.rectangle(frame, (x, y), (x+w, y+h), (0, 0, 255), 2)\n",
    "\n",
    "    # Mostrar el fotograma con los resultados en una ventana\n",
    "    cv.imshow('frame', frame)\n",
    "    \n",
    "    # Esperar 1 milisegundo por una tecla, si es 'Esc' (código 27), salir del bucle\n",
    "    k = cv.waitKey(1)\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "# Liberar la cámara y cerrar todas las ventanas de OpenCV\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b778cd-c937-4f2c-866b-3d997a8116ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8bbf8606-d031-4846-a5fa-5f5a308784f4",
   "metadata": {},
   "source": [
    "# Genera el XML de Emociones\n",
    "\n",
    "# Resumen del Código\n",
    ":\r\n",
    "\r\n",
    "1. **Importación de Librerías:**\r\n",
    "   - `cv2` para procesamiento de imágenes.\r\n",
    "   - `numpy` para manejo de arreglos.\r\n",
    "   - `os` para manejo del sistema de archivos.\r\n",
    "\r\n",
    "2. **Definición del Conjunto de Datos:**\r\n",
    "   - Se especifica la ruta del directorio con imágenes etiquetadas de rostros.\r\n",
    "\r\n",
    "3. **Lectura y Procesamiento de Datos:**\r\n",
    "   - Se obtiene una lista de los nombres de los subdirectorios (cada uno representando una persona).\r\n",
    "   - Se inicializan listas para almacenar las etiquetas y los datos de las imágenes.\r\n",
    "   - Para cada subdirectorio, se leen las imágenes en escala de grises y se almacenan junto con sus etiquetas correspondientes.\r\n",
    "\r\n",
    "4. **Entrenamiento del Modelo:**\r\n",
    "   - Se crea un reconocedor facial LBPH.\r\n",
    "   - Se entrena el reconocedor con las imágenes y sus etiquetas.\r\n",
    "\r\n",
    "5. **Guardado del Modelo:**\r\n",
    "   - El modelo entrenado se guarda en un archivo XML para su uso posterior.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fd4f8b-2d8d-47dd-a72f-aadbf9eaf8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv \n",
    "import numpy as np \n",
    "import os\n",
    "\n",
    "# Ruta del conjunto de datos que contiene las imágenes etiquetadas de los rostros\n",
    "dataSet = 'D:\\\\Escuela Betin\\\\9no Sem\\\\3. Inteligencia Artificial\\\\Emociones\\\\Emociones3'\n",
    "\n",
    "# Obtener los nombres de los directorios dentro del conjunto de datos\n",
    "faces  = os.listdir(dataSet)\n",
    "print(faces)\n",
    "\n",
    "# Inicializar listas para las etiquetas y los datos de las caras\n",
    "labels = []\n",
    "facesData = []\n",
    "label = 0 \n",
    "\n",
    "# Iterar sobre cada directorio en el conjunto de datos\n",
    "for face in faces:\n",
    "    facePath = dataSet + '\\\\' + face  # Ruta del directorio de cada persona\n",
    "    for faceName in os.listdir(facePath):\n",
    "        labels.append(label)  # Agregar la etiqueta correspondiente a la lista de etiquetas\n",
    "        # Leer la imagen en escala de grises y agregarla a la lista de datos de caras\n",
    "        facesData.append(cv.imread(facePath + '\\\\' + faceName, 0))\n",
    "    label = label + 1  # Incrementar la etiqueta para la siguiente persona\n",
    "\n",
    "# Crear un reconocedor facial LBPH\n",
    "faceRecognizer = cv.face.LBPHFaceRecognizer_create()\n",
    "\n",
    "# Entrenar el reconocedor con los datos de las caras y sus etiquetas\n",
    "faceRecognizer.train(facesData, np.array(labels))\n",
    "\n",
    "# Guardar el modelo entrenado en un archivo XML\n",
    "faceRecognizer.write('D:\\\\Escuela Betin\\\\9no Sem\\\\3. Inteligencia Artificial\\\\Emociones\\\\EmocionesLBPHZwei.xml')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69306535-ccc7-4c07-a2a8-6d794e8ff63a",
   "metadata": {},
   "source": [
    "# Correr XML\n",
    "\n",
    "Aqui se corre el xml junto con el haarcascade para correr  el xml de las emociones.\n",
    "\n",
    "## Resumen del Código\r",
    "a:\r\n",
    "\r\n",
    "1. **Importación de Librerías:**\r\n",
    "   - `cv2` para visión por computadora.\r\n",
    "   - `os` para manejo de archivos del sistema.\r\n",
    "\r\n",
    "2. **Carga del Modelo:**\r\n",
    "   - Se crea un reconocedor LBPH y se carga un modelo preentrenado desde un archivo XML.\r\n",
    "\r\n",
    "3. **Preparación del Conjunto de Datos:**\r\n",
    "   - Se especifica la ruta del directorio que contiene imágenes etiquetadas de rostros.\r\n",
    "\r\n",
    "4. **Inicialización de la Cámara:**\r\n",
    "   - Se inicia la captura de video desde la cámara web.\r\n",
    "   - Se carga un clasificador Haar para la detección de rostros.\r\n",
    "\r\n",
    "5. **Procesamiento en Tiempo Real:**\r\n",
    "   - Se captura cada fotograma de la cámara.\r\n",
    "   - Se convierte el fotograma a escala de grises.\r\n",
    "   - Se detectan rostros en la imagen en escala de grises.\r\n",
    "\r\n",
    "6. **Reconocimiento Facial:**\r\n",
    "   - Para cada rostro detectado, se extrae y redimensiona la región de interés.\r\n",
    "   - Se realiza la predicción utilizando el modelo LBPH.\r\n",
    "   - Se muestra el resultado en el fotograma:\r\n",
    "     - Si la confianza es menor a 100, se muestra el nombre y un rectángulo verde.\r\n",
    "     - Si la confianza es mayor o igual a 100, se etiqueta como \"Desconocido\" y se dibuja un rectángulo rojo.\r\n",
    "\r\n",
    "7. **Visualización y Salida:**\r\n",
    "   - Se muestra el fotograma con los resultados en una ventana.\r\n",
    "   - Se espera la tecla 'Esc' para salir del bucle y finalizar el programa.\r\n",
    "\r\n",
    "8. **Liberación de Recursos:**\r\n",
    "   - Se liberan los recursos de la cámara y se cierran las ventanas de OpenCV.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "877fbcd0-49cb-45d8-9c5f-5b3883df5597",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import os \n",
    "\n",
    "# Crear el reconocedor facial LBPH y cargar el modelo preentrenado\n",
    "faceRecognizer = cv.face.LBPHFaceRecognizer_create()\n",
    "faceRecognizer.read('D:\\\\Escuela Betin\\\\9no Sem\\\\3. Inteligencia Artificial\\\\Emociones\\\\EmocionesLBPHZwei.xml')\n",
    "\n",
    "# Definir la ruta del conjunto de datos que contiene las etiquetas de las caras\n",
    "dataSet = 'D:\\\\Escuela Betin\\\\9no Sem\\\\3. Inteligencia Artificial\\\\Emociones\\\\Emociones3'\n",
    "faces = os.listdir(dataSet)  # Obtener los nombres de los archivos en el directorio\n",
    "\n",
    "# Iniciar la captura de video desde la cámara web\n",
    "cap = cv.VideoCapture(0)\n",
    "\n",
    "# Cargar el clasificador Haar para la detección de rostros\n",
    "rostro = cv.CascadeClassifier('D:\\\\Escuela Betin\\\\9no Sem\\\\3. Inteligencia Artificial\\\\Material de clase\\\\haarcascade_frontalface_alt.xml')\n",
    "\n",
    "while True:\n",
    "    # Leer un fotograma de la cámara\n",
    "    ret, frame = cap.read()\n",
    "    if ret == False: \n",
    "        break  # Salir del bucle si no se puede leer el fotograma\n",
    "\n",
    "    # Convertir el fotograma a escala de grises\n",
    "    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    cpGray = gray.copy()  # Hacer una copia de la imagen en grises\n",
    "\n",
    "    # Detectar rostros en la imagen en escala de grises\n",
    "    rostros = rostro.detectMultiScale(gray, 1.3, 3)\n",
    "    \n",
    "    for (x, y, w, h) in rostros:\n",
    "        # Extraer la región de interés (ROI) que contiene el rostro detectado\n",
    "        frame2 = cpGray[y:y+h, x:x+w]\n",
    "        \n",
    "        # Redimensionar la ROI a 100x100 píxeles\n",
    "        frame2 = cv.resize(frame2,  (100, 100), interpolation=cv.INTER_CUBIC)\n",
    "        \n",
    "        # Realizar la predicción de la cara utilizando el modelo LBPH\n",
    "        result = faceRecognizer.predict(frame2)\n",
    "        \n",
    "        # Mostrar el resultado de la predicción en el fotograma\n",
    "        cv.putText(frame, '{}'.format(result), (x, y-20), 1, 3.3, (255, 255, 0), 1, cv.LINE_AA)\n",
    "        \n",
    "        if result[1] < 100:\n",
    "            # Si la confianza es menor a 100, se considera una coincidencia y se muestra el nombre\n",
    "            cv.putText(frame, '{}'.format(faces[result[0]]), (x, y-25), 2, 1.1, (0, 255, 0), 1, cv.LINE_AA)\n",
    "            cv.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        else:\n",
    "            # Si la confianza es mayor o igual a 100, se considera \"Desconocido\"\n",
    "            cv.putText(frame, 'Desconocido', (x, y-20), 2, 0.8, (0, 0, 255), 1, cv.LINE_AA)\n",
    "            cv.rectangle(frame, (x, y), (x+w, y+h), (0, 0, 255), 2)\n",
    "\n",
    "    # Mostrar el fotograma con los resultados en una ventana\n",
    "    cv.imshow('frame', frame)\n",
    "    \n",
    "    # Esperar 1 milisegundo por una tecla, si es 'Esc' (código 27), salir del bucle\n",
    "    k = cv.waitKey(1)\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "# Liberar la cámara y cerrar todas las ventanas de OpenCV\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7faf3de1-795e-4223-b101-ddd01c6ce909",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
